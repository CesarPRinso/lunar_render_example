{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TT3LPGc5PuK"
      },
      "source": [
        "\n",
        "\n",
        "<p><img height=\"80px\" src=\"https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/UPM/Escudo/EscUpm.jpg\" align=\"left\" hspace=\"0px\" vspace=\"0px\"></p>\n",
        "\n",
        "**Course \"Artificial Neural Networks and Deep Learning\" - Universidad Politécnica de Madrid (UPM)**\n",
        "\n",
        "# **Deep Q-Learning for Cartpole**\n",
        "\n",
        "This notebook includes an implementation of the Deep Q-learning (DQN) algorithm for the cartpole problem (see [OpenAI's Cartpole](https://www.gymlibrary.dev/environments/classic_control/cart_pole/)).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXBzOdaLAEUn"
      },
      "source": [
        "##Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWuO-YBuPzwz",
        "outputId": "87d4bec1-aa60-46d6-a756-f6487398d434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.8/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (5.2.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (1.5.0)\n",
            "Collecting box2d-py==2.3.5\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygame==2.1.0\n",
            "  Downloading pygame-2.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting swig==4.*\n",
            "  Downloading swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym[box2d]) (3.11.0)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for box2d-py\n",
            "Failed to build box2d-py\n",
            "Installing collected packages: swig, box2d-py, pygame\n",
            "  Running setup.py install for box2d-py ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: box2d-py was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. Discussion can be found at https://github.com/pypa/pip/issues/8368\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed box2d-py-2.3.5 pygame-2.1.0 swig-4.1.1\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m968.6/968.6 KB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install gym[box2d]\n",
        "!pip install gym pyvirtualdisplay --quiet\n",
        "!pip install pyglet --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iLYLdwHdDTrR"
      },
      "outputs": [],
      "source": [
        "!apt-get install x11-utils > /dev/null 2>&1 \n",
        "!pip install pyglet > /dev/null 2>&1 \n",
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LjLS1WetFhCE"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBrRuhN1AQ-s"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4N2yVwtuFlBu"
      },
      "outputs": [],
      "source": [
        "GAMMA = 0.99\n",
        "MEMORY_SIZE = 500000\n",
        "LEARNING_RATE = 6.3e-4\n",
        "BATCH_SIZE = 128\n",
        "EXPLORATION_MAX = 1.0\n",
        "EXPLORATION_MIN = 0.01\n",
        "EXPLORATION_DECAY = 0.005 #0.995\n",
        "NUMBER_OF_EPISODES = 1200\n",
        "MAX_STEPS = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoGaas6TAd6p"
      },
      "source": [
        "## Class ReplayMemory\n",
        "\n",
        "Memory of transitions for experience replay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cQV7IfhFOoSh"
      },
      "outputs": [],
      "source": [
        "class ReplayMemory:\n",
        "\n",
        "    def __init__(self,number_of_observations):\n",
        "        # Create replay memory\n",
        "        self.states = np.zeros((MEMORY_SIZE, number_of_observations))\n",
        "        self.states_next = np.zeros((MEMORY_SIZE, number_of_observations))\n",
        "        self.actions = np.zeros(MEMORY_SIZE, dtype=np.int32)\n",
        "        self.rewards = np.zeros(MEMORY_SIZE)\n",
        "        self.terminal_states = np.zeros(MEMORY_SIZE, dtype=bool)\n",
        "        self.current_size=0\n",
        "\n",
        "    def store_transition(self, state, action, reward, state_next, terminal_state):\n",
        "        # Store a transition (s,a,r,s') in the replay memory\n",
        "        i = self.current_size % MEMORY_SIZE\n",
        "        self.states[i] = state\n",
        "        self.states_next[i] = state_next\n",
        "        self.actions[i] = action\n",
        "        self.rewards[i] = reward\n",
        "        self.terminal_states[i] = terminal_state\n",
        "        self.current_size = self.current_size + 1\n",
        "\n",
        "    def sample_memory(self, batch_size):\n",
        "        # Generate a sample of transitions from the replay memory\n",
        "        batch = np.random.choice(self.current_size, batch_size) % MEMORY_SIZE\n",
        "        states = self.states[batch]\n",
        "        states_next = self.states_next[batch]\n",
        "        rewards = self.rewards[batch]\n",
        "        actions = self.actions[batch]   \n",
        "        terminal_states = self.terminal_states[batch]  \n",
        "        return states, actions, rewards, states_next, terminal_states"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(number_of_observations,number_of_actions):\n",
        "        model = keras.models.Sequential()\n",
        "        model.add(keras.layers.Dense(256, input_shape=(number_of_observations,), \\\n",
        "                             activation=\"relu\"))\n",
        "        model.add(keras.layers.Dense(256, activation=\"relu\"))\n",
        "\n",
        "        model.add(keras.layers.Dense(number_of_actions, activation=None))\n",
        "        model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE))\n",
        "        return model"
      ],
      "metadata": {
        "id": "TmiuNlKrhHtr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gejKO0OYAsS4"
      },
      "source": [
        "## Class DQN\n",
        "\n",
        "Reinforcement learning agent with a Deep Q-Network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NZ6P4Gj0FtnU"
      },
      "outputs": [],
      "source": [
        "class DQN:\n",
        "\n",
        "    def __init__(self, number_of_observations, number_of_actions):\n",
        "        # Initialize variables and create neural model\n",
        "        self.exploration_rate = EXPLORATION_MAX\n",
        "        self.number_of_actions = number_of_actions\n",
        "        self.number_of_observations = number_of_observations\n",
        "        self.scores = []\n",
        "        self.memory = ReplayMemory(number_of_observations)\n",
        "        self.model = create_model(number_of_observations,number_of_actions)\n",
        "        self.target = create_model(number_of_observations,number_of_actions)\n",
        "        self.update_target = 250\n",
        "        self.update_step =0\n",
        "        self.tau = 0.005 #a veces aparece esto pero no se como meterlo :(\n",
        "       \n",
        "\n",
        "    def remember(self, state, action, reward, next_state, terminal_state):\n",
        "        # Store a tuple (s, a, r, s') for experience replay\n",
        "        state = np.reshape(state, [1, self.number_of_observations])\n",
        "        next_state = np.reshape(next_state, [1, self.number_of_observations])\n",
        "        self.memory.store_transition(state, action, reward, next_state, terminal_state)\n",
        "\n",
        "    def select(self, state):\n",
        "        # Generate an action for a given state using epsilon-greedy policy\n",
        "        if np.random.rand() < self.exploration_rate:\n",
        "            return random.randrange(self.number_of_actions)\n",
        "        else:\n",
        "            state = np.reshape(state, [1, self.number_of_observations])\n",
        "            q_values = self.model.predict(state, verbose=0)\n",
        "            #print(q_values, \"qvalues\")\n",
        "            return np.argmax(q_values[0])\n",
        "\n",
        "    def learn(self):\n",
        "        # Learn the value Q using a sample of examples from the replay memory\n",
        "        if self.memory.current_size < BATCH_SIZE: return\n",
        "\n",
        "        if self.update_step % self.update_target ==0:\n",
        "            self.target.set_weights(self.model.get_weights())\n",
        "        states, actions, rewards, next_states, terminal_states = self.memory.sample_memory(BATCH_SIZE)\n",
        "\n",
        "        q_targets = self.model.predict(states, verbose=0)\n",
        "        q_next_states = self.target.predict(next_states, verbose=0) #modify esto \n",
        "        for i in range(BATCH_SIZE):\n",
        "             q_val = rewards[i]\n",
        "             max_action = np.argmax(q_next_states[i]) #esto es la duda si usar next_q o usar q_next_states\n",
        "             if not terminal_states[i]:\n",
        "               q_val+= GAMMA * q_next_states[i][max_action]\n",
        "\n",
        "\n",
        "             q_targets[i][actions[i]] = q_val\n",
        "             \"\"\"if (terminal_states[i]):\n",
        "                  q_targets[i][actions[i]] = rewards[i]\n",
        "             else:\n",
        "                  q_targets[i][actions[i]] = rewards[i] + GAMMA * np.max(q_next_states[i]) \"\"\"   \n",
        "\n",
        "        self.model.train_on_batch(states, q_targets)\n",
        "        self.update_step +=1\n",
        "\n",
        "        # Decrease exploration rate\n",
        "        self.exploration_rate -= EXPLORATION_DECAY\n",
        "        self.exploration_rate = max(EXPLORATION_MIN, self.exploration_rate)\n",
        "\n",
        "    def add_score(self, score):\n",
        "       # Add the obtained score in a list to be presented later\n",
        "        self.scores.append(score)\n",
        "\n",
        "    def display_scores_graphically(self):\n",
        "        # Display the obtained scores graphically\n",
        "        plt.plot(self.scores)\n",
        "        plt.xlabel(\"Episode\")\n",
        "        plt.ylabel(\"Score\")            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-YSpziT0K9I"
      },
      "source": [
        "## Environment Lunar Lander v2\n",
        "\n",
        "Lunar lander simulator from Open Ai Gym:\n",
        "\n",
        "<p><img height=\"200px\" src=\"https://www.gymlibrary.dev/_images/lunar_lander.gif\" align=\"center\" vspace=\"20px\"</p>\n",
        "\n",
        "This environment is a classic rocket trajectory optimization problem.\n",
        "    According to Pontryagin's maximum principle, it is optimal to fire the\n",
        "    engine at full throttle or turn it off. This is the reason why this\n",
        "    environment has discrete actions: engine on or off.\n",
        "    There are two environment versions: discrete or continuous.\n",
        "    The landing pad is always at coordinates (0,0). The coordinates are the\n",
        "    first two numbers in the state vector.\n",
        "    Landing outside of the landing pad is possible. Fuel is infinite, so an agent\n",
        "    can learn to fly and then land on its first attempt.\n",
        "\n",
        "State vector:\n",
        "The state is an 8-dimensional vector: the coordinates of the lander in `x` & `y`, its linear\n",
        "    velocities in `x` & `y`, its angle, its angular velocity, and two booleans\n",
        "    that represent whether each leg is in contact with the ground or not.\n",
        "    \n",
        "    \n",
        "An episode is considered a solution if it scores at least 200 points.\n",
        "\n",
        "Actions:\n",
        "There are four discrete actions available: \n",
        "\n",
        "-do nothing, \n",
        "\n",
        "-fire left orientation engine, \n",
        "\n",
        "-fire main engine, \n",
        "\n",
        "-fire right orientation engine.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YuHhDKV5COE0"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4smjhKduCY2T"
      },
      "outputs": [],
      "source": [
        "from gym import spaces\n",
        "from gym.wrappers import RecordVideo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVGAJOjUCcM1",
        "outputId": "2279e87f-1020-4ffe-aa85-7a06660f154e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7ff5a33f0f10>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JX3S0ABQCzxh"
      },
      "outputs": [],
      "source": [
        "def wrap(env):\n",
        "  env = RecordVideo(env,'./video',episode_trigger= lambda x: x % 10 ==0)\n",
        "  return env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4LBloUSG0LmT"
      },
      "outputs": [],
      "source": [
        "def create_environment():\n",
        "    # Create simulated environment\n",
        "    environment = gym.make(\"LunarLander-v2\")\n",
        "    \n",
        "    number_of_observations = environment.observation_space.shape[0]\n",
        "    number_of_actions = environment.action_space.n\n",
        "    print(number_of_actions,number_of_observations)\n",
        "    #environment = wrap(environment)\n",
        "    return environment, number_of_observations, number_of_actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbbw6blhDcsJ"
      },
      "source": [
        "## Main program\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tzO5MNvjD6Qw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yuzI0m5u5vVf",
        "outputId": "4b530593-912a-466a-b257-a1691755c0ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode   1: score -304.68552868036704 Episode 1 Score: -304.68552868036704 AVG_score: -304.68552868036704 AVG_REWARD -304.68552868036704 Exploration rate 1.0 Mem size  123\n",
            "Episode   2: score -164.03217100650184 Episode 2 Score: -164.03217100650184 AVG_score: -234.35884984343443 AVG_REWARD -269.52218926190073 Exploration rate 0.6049999999999996 Mem size  206\n",
            "Episode   3: score -348.03182232352293 Episode 3 Score: -348.03182232352293 AVG_score: -272.2498406701306 AVG_REWARD -270.43140639797736 Exploration rate 0.17499999999999927 Mem size  292\n",
            "Episode   4: score -97.19434483980355 Episode 4 Score: -97.19434483980355 AVG_score: -228.48596671254882 AVG_REWARD -259.94504647662023 Exploration rate 0.01 Mem size  407\n",
            "Episode   5: score -234.51308833829245 Episode 5 Score: -234.51308833829245 AVG_score: -229.69139103769754 AVG_REWARD -253.89431538883568 Exploration rate 0.01 Mem size  524\n",
            "Episode   6: score -203.2091331095344 Episode 6 Score: -203.2091331095344 AVG_score: -225.27768138300368 AVG_REWARD -249.12487638786368 Exploration rate 0.01 Mem size  638\n",
            "Episode   7: score -338.4225282954688 Episode 7 Score: -338.4225282954688 AVG_score: -241.44123094192724 AVG_REWARD -248.0272127527299 Exploration rate 0.01 Mem size  751\n",
            "Episode   8: score -220.45423492759846 Episode 8 Score: -220.45423492759846 AVG_score: -238.81785644013615 AVG_REWARD -246.8760432136557 Exploration rate 0.01 Mem size  839\n",
            "Episode   9: score -326.0112573130316 Episode 9 Score: -326.0112573130316 AVG_score: -248.50601209268007 AVG_REWARD -247.05715086688062 Exploration rate 0.01 Mem size  906\n",
            "Episode  10: score -373.1442937987439 Episode 10 Score: -373.1442937987439 AVG_score: -260.96984026328647 AVG_REWARD -248.44841980652123 Exploration rate 0.01 Mem size  1118\n",
            "Episode  11: score -492.3894629313575 Episode 11 Score: -492.3894629313575 AVG_score: -282.0079877785657 AVG_REWARD -251.49928962216163 Exploration rate 0.01 Mem size  1284\n",
            "Episode  12: score -434.13070030973677 Episode 12 Score: -434.13070030973677 AVG_score: -294.6848804894966 AVG_REWARD -255.09808886110622 Exploration rate 0.01 Mem size  1778\n",
            "Episode  13: score -84.64638907548623 Episode 13 Score: -84.64638907548623 AVG_score: -278.5280734576496 AVG_REWARD -256.9003953685326 Exploration rate 0.01 Mem size  1990\n",
            "Episode  14: score -358.63966075403783 Episode 14 Score: -358.63966075403783 AVG_score: -284.2503296931059 AVG_REWARD -258.85396210600214 Exploration rate 0.01 Mem size  2286\n",
            "Episode  15: score -333.10097615085783 Episode 15 Score: -333.10097615085783 AVG_score: -287.507039456956 AVG_REWARD -260.7641672627324 Exploration rate 0.01 Mem size  2460\n",
            "Episode  16: score -306.2570091035987 Episode 16 Score: -306.2570091035987 AVG_score: -288.67891255987126 AVG_REWARD -262.5088388438036 Exploration rate 0.01 Mem size  2782\n",
            "Episode  17: score -180.3663527389179 Episode 17 Score: -180.3663527389179 AVG_score: -282.3075855115799 AVG_REWARD -263.67347100073164 Exploration rate 0.01 Mem size  3089\n",
            "Episode  18: score -366.42907332279475 Episode 18 Score: -366.42907332279475 AVG_score: -286.98100150109184 AVG_REWARD -264.96833380630716 Exploration rate 0.01 Mem size  4046\n",
            "Episode  19: score -225.08642797532173 Episode 19 Score: -225.08642797532173 AVG_score: -283.7233923681565 AVG_REWARD -265.9554421516676 Exploration rate 0.01 Mem size  5041\n",
            "Episode  20: score -111.99877125201837 Episode 20 Score: -111.99877125201837 AVG_score: -275.13716131234963 AVG_REWARD -266.41452810970173 Exploration rate 0.01 Mem size  5155\n",
            "Episode  21: score 184.88724595596926 Episode 21 Score: 184.88724595596926 AVG_score: -253.23123715671542 AVG_REWARD -265.78675235003567 Exploration rate 0.01 Mem size  5740\n",
            "Episode  22: score 192.6623399617193 Episode 22 Score: 192.6623399617193 AVG_score: -232.96334728769568 AVG_REWARD -264.2947793926566 Exploration rate 0.01 Mem size  6221\n",
            "Episode  23: score -128.45244387376832 Episode 23 Score: -128.45244387376832 AVG_score: -228.419394965351 AVG_REWARD -262.7349800697303 Exploration rate 0.01 Mem size  6956\n",
            "Episode  24: score -62.871436810858356 Episode 24 Score: -62.871436810858356 AVG_score: -221.52156337558048 AVG_REWARD -261.01775437414074 Exploration rate 0.01 Mem size  7956\n",
            "Episode  25: score -52.024631151497246 Episode 25 Score: -52.024631151497246 AVG_score: -214.74168608661716 AVG_REWARD -259.16671164263977 Exploration rate 0.01 Mem size  8173\n",
            "Episode  26: score -74.69770821193649 Episode 26 Score: -74.69770821193649 AVG_score: -209.35537924528327 AVG_REWARD -257.25089116581836 Exploration rate 0.01 Mem size  8253\n",
            "Episode  27: score -92.77201145105742 Episode 27 Score: -92.77201145105742 AVG_score: -205.03747673438605 AVG_REWARD -255.31706100169126 Exploration rate 0.01 Mem size  9253\n",
            "Episode  28: score 189.37989874240913 Episode 28 Score: 189.37989874240913 AVG_score: -190.95114189592908 AVG_REWARD -253.01827817648547 Exploration rate 0.01 Mem size  9497\n",
            "Episode  29: score 3.261667325071869 Episode 29 Score: 3.261667325071869 AVG_score: -184.25414847451523 AVG_REWARD -250.64710129021063 Exploration rate 0.01 Mem size  9637\n",
            "Episode  30: score -73.18837797092324 Episode 30 Score: -73.18837797092324 AVG_score: -180.5519561243955 AVG_REWARD -248.31059645135014 Exploration rate 0.01 Mem size  10031\n",
            "Episode  31: score -32.45066844491325 Episode 31 Score: -32.45066844491325 AVG_score: -175.77449523150898 AVG_REWARD -245.97072221845204 Exploration rate 0.01 Mem size  10288\n",
            "Episode  32: score -65.72599664660909 Episode 32 Score: -65.72599664660909 AVG_score: -172.33547965073083 AVG_REWARD -243.66962088821074 Exploration rate 0.01 Mem size  10490\n",
            "Episode  33: score -162.91413842138417 Episode 33 Score: -162.91413842138417 AVG_score: -172.04998446196277 AVG_REWARD -241.49932887529414 Exploration rate 0.01 Mem size  10627\n",
            "Episode  34: score -28.403404955494224 Episode 34 Score: -28.403404955494224 AVG_score: -167.82508506471368 AVG_REWARD -239.33243935145353 Exploration rate 0.01 Mem size  10770\n",
            "Episode  35: score -87.85660913449925 Episode 35 Score: -87.85660913449925 AVG_score: -165.54027146670754 AVG_REWARD -237.22409169760363 Exploration rate 0.01 Mem size  10931\n",
            "Episode  36: score -65.6998778507279 Episode 36 Score: -65.6998778507279 AVG_score: -162.766927199597 AVG_REWARD -235.15583712821456 Exploration rate 0.01 Mem size  11156\n",
            "Episode  37: score -52.92246703217053 Episode 37 Score: -52.92246703217053 AVG_score: -159.79815800588278 AVG_REWARD -233.11914309788125 Exploration rate 0.01 Mem size  12156\n",
            "Episode  38: score 227.88905491416963 Episode 38 Score: 227.88905491416963 AVG_score: -149.5958629290393 AVG_REWARD -230.92116204080648 Exploration rate 0.01 Mem size  12661\n",
            "Episode  39: score -82.57211718781056 Episode 39 Score: -82.57211718781056 AVG_score: -147.87730534593086 AVG_REWARD -228.79183238196353 Exploration rate 0.01 Mem size  12860\n",
            "Episode  40: score -171.89646356668032 Episode 40 Score: -171.89646356668032 AVG_score: -148.4777843014496 AVG_REWARD -226.78398117995067 Exploration rate 0.01 Mem size  13332\n",
            "Episode  41: score -5.330480034450145 Episode 41 Score: -5.330480034450145 AVG_score: -144.98638663640082 AVG_REWARD -224.78891789840068 Exploration rate 0.01 Mem size  14332\n",
            "Episode  42: score -47.0393009870972 Episode 42 Score: -47.0393009870972 AVG_score: -142.65431316856024 AVG_REWARD -222.83333207149968 Exploration rate 0.01 Mem size  14428\n",
            "Episode  43: score -87.54905616167972 Episode 43 Score: -87.54905616167972 AVG_score: -141.37279556374907 AVG_REWARD -220.93890098992412 Exploration rate 0.01 Mem size  14531\n",
            "Episode  44: score 209.98933217248558 Episode 44 Score: 209.98933217248558 AVG_score: -133.38729266065283 AVG_REWARD -218.9490917097134 Exploration rate 0.01 Mem size  14944\n",
            "Episode  45: score -44.2593510876748 Episode 45 Score: -44.2593510876748 AVG_score: -131.40667173680887 AVG_REWARD -217.0037045992044 Exploration rate 0.01 Mem size  15193\n",
            "Episode  46: score 213.4838457036452 Episode 46 Score: 213.4838457036452 AVG_score: -123.9090517924512 AVG_REWARD -214.9799077990576 Exploration rate 0.01 Mem size  15633\n",
            "Episode  47: score -37.605943407155756 Episode 47 Score: -37.605943407155756 AVG_score: -122.07281544382788 AVG_REWARD -213.00316115320163 Exploration rate 0.01 Mem size  16633\n",
            "Episode  48: score -68.01057484391328 Episode 48 Score: -68.01057484391328 AVG_score: -120.94651876466298 AVG_REWARD -211.08531443677376 Exploration rate 0.01 Mem size  17633\n",
            "Episode  49: score -47.11888004152229 Episode 49 Score: -47.11888004152229 AVG_score: -119.43983226010909 AVG_REWARD -209.21499847398468 Exploration rate 0.01 Mem size  18633\n",
            "Episode  50: score -46.506909903724605 Episode 50 Score: -46.506909903724605 AVG_score: -117.9811738129814 AVG_REWARD -207.3903219807646 Exploration rate 0.01 Mem size  19633\n",
            "Episode  51: score -185.8816449572857 Episode 51 Score: -185.8816449572857 AVG_score: -119.31255560012463 AVG_REWARD -205.66330695369325 Exploration rate 0.01 Mem size  20436\n",
            "Episode  52: score 157.73410127971363 Episode 52 Score: 157.73410127971363 AVG_score: -113.98473527551235 AVG_REWARD -203.90025749834362 Exploration rate 0.01 Mem size  21081\n",
            "Episode  53: score -205.58955894067304 Episode 53 Score: -205.58955894067304 AVG_score: -115.713128174855 AVG_REWARD -202.23634939790045 Exploration rate 0.01 Mem size  22022\n",
            "Episode  54: score -195.81778132771137 Episode 54 Score: -195.81778132771137 AVG_score: -117.19654767768569 AVG_REWARD -200.6615382549335 Exploration rate 0.01 Mem size  22781\n",
            "Episode  55: score -92.10667490391434 Episode 55 Score: -92.10667490391434 AVG_score: -116.74036817270803 AVG_REWARD -199.13569879889306 Exploration rate 0.01 Mem size  23781\n",
            "Episode  56: score -96.51339044661884 Episode 56 Score: -96.51339044661884 AVG_score: -116.379172141885 AVG_REWARD -197.65790368001788 Exploration rate 0.01 Mem size  24238\n",
            "Episode  57: score -191.26742989921684 Episode 57 Score: -191.26742989921684 AVG_score: -117.69300122534696 AVG_REWARD -196.25501065449734 Exploration rate 0.01 Mem size  25234\n",
            "Episode  58: score -57.17303238975661 Episode 58 Score: -57.17303238975661 AVG_score: -116.64955348680229 AVG_REWARD -194.8825027722957 Exploration rate 0.01 Mem size  25429\n",
            "Episode  59: score -78.32236987673961 Episode 59 Score: -78.32236987673961 AVG_score: -115.9999402052758 AVG_REWARD -193.54551018641402 Exploration rate 0.01 Mem size  25573\n",
            "Episode  60: score -78.36718141134475 Episode 60 Score: -78.36718141134475 AVG_score: -115.3727275587103 AVG_REWARD -192.2426304759523 Exploration rate 0.01 Mem size  25970\n",
            "Episode  61: score 203.60156849413931 Episode 61 Score: 203.60156849413931 AVG_score: -110.14364073817178 AVG_REWARD -190.89674539828374 Exploration rate 0.01 Mem size  26768\n",
            "Episode  62: score -7.972412230634225 Episode 62 Score: -7.972412230634225 AVG_score: -108.49571769772763 AVG_REWARD -189.5676965644038 Exploration rate 0.01 Mem size  27768\n",
            "Episode  63: score -56.36438622441512 Episode 63 Score: -56.36438622441512 AVG_score: -107.66823624577029 AVG_REWARD -188.26770513077471 Exploration rate 0.01 Mem size  28768\n",
            "Episode  64: score -44.79047315889326 Episode 64 Score: -44.79047315889326 AVG_score: -106.68577119753783 AVG_REWARD -186.9929874130679 Exploration rate 0.01 Mem size  29768\n",
            "Episode  65: score -327.7336039726764 Episode 65 Score: -327.7336039726764 AVG_score: -110.0865070863861 AVG_REWARD -185.8098107926574 Exploration rate 0.01 Mem size  30201\n",
            "Episode  66: score 177.81654764786958 Episode 66 Score: 177.81654764786958 AVG_score: -105.72433959041254 AVG_REWARD -184.59639456232037 Exploration rate 0.01 Mem size  30876\n",
            "Episode  67: score -54.77754353399428 Episode 67 Score: -54.77754353399428 AVG_score: -104.96393964927196 AVG_REWARD -183.40785045914055 Exploration rate 0.01 Mem size  31876\n",
            "Episode  68: score 133.78753653194912 Episode 68 Score: 133.78753653194912 AVG_score: -101.4528885289599 AVG_REWARD -182.20263043075553 Exploration rate 0.01 Mem size  32489\n",
            "Episode  69: score 201.1852546991528 Episode 69 Score: 201.1852546991528 AVG_score: -97.06682848217565 AVG_REWARD -180.9687782286022 Exploration rate 0.01 Mem size  33265\n",
            "Episode  70: score -64.52495936657748 Episode 70 Score: -64.52495936657748 AVG_score: -96.60194463766712 AVG_REWARD -179.7635377487317 Exploration rate 0.01 Mem size  34265\n",
            "Episode  71: score 5.700239037623106 Episode 71 Score: 5.700239037623106 AVG_score: -95.16106881125458 AVG_REWARD -178.57195367918976 Exploration rate 0.01 Mem size  35265\n",
            "Episode  72: score -28.180944736294897 Episode 72 Score: -28.180944736294897 AVG_score: -94.23078931021347 AVG_REWARD -177.40054861850953 Exploration rate 0.01 Mem size  36265\n",
            "Episode  73: score -56.189801656732705 Episode 73 Score: -56.189801656732705 AVG_score: -93.70967989030278 AVG_REWARD -176.25409836195874 Exploration rate 0.01 Mem size  37265\n",
            "Episode  74: score -1.257291757282971 Episode 74 Score: -1.257291757282971 AVG_score: -92.46032329391062 AVG_REWARD -175.12175005022834 Exploration rate 0.01 Mem size  37452\n",
            "Episode  75: score -80.60957804870667 Episode 75 Score: -80.60957804870667 AVG_score: -92.30231335730791 AVG_REWARD -174.01749089432275 Exploration rate 0.01 Mem size  38452\n",
            "Episode  76: score -43.69026747250332 Episode 76 Score: -43.69026747250332 AVG_score: -91.66268117461311 AVG_REWARD -172.93387497695815 Exploration rate 0.01 Mem size  39452\n",
            "Episode  77: score -87.15530824548945 Episode 77 Score: -87.15530824548945 AVG_score: -91.60414386384527 AVG_REWARD -171.87764470276187 Exploration rate 0.01 Mem size  40452\n",
            "Episode  78: score 222.22546081872377 Episode 78 Score: 222.22546081872377 AVG_score: -87.58068739355592 AVG_REWARD -170.79691448084898 Exploration rate 0.01 Mem size  41110\n",
            "Episode  79: score 37.68864119662137 Episode 79 Score: 37.68864119662137 AVG_score: -85.99499968988279 AVG_REWARD -169.7234725214697 Exploration rate 0.01 Mem size  42110\n",
            "Episode  80: score 196.8388625657218 Episode 80 Score: 196.8388625657218 AVG_score: -82.45957641168772 AVG_REWARD -168.6326738200974 Exploration rate 0.01 Mem size  42458\n",
            "Episode  81: score 224.51337025426093 Episode 81 Score: 224.51337025426093 AVG_score: -78.66978694667601 AVG_REWARD -167.52202089573416 Exploration rate 0.01 Mem size  43119\n",
            "Episode  82: score -167.20586441863088 Episode 82 Score: -167.20586441863088 AVG_score: -79.74949520852913 AVG_REWARD -166.45162424101215 Exploration rate 0.01 Mem size  43237\n",
            "Episode  83: score 193.76067797750116 Episode 83 Score: 193.76067797750116 AVG_score: -76.45419191713117 AVG_REWARD -165.36731782747142 Exploration rate 0.01 Mem size  43510\n",
            "Episode  84: score -50.43421321318511 Episode 84 Score: -50.43421321318511 AVG_score: -76.14443026589372 AVG_REWARD -164.30514059459549 Exploration rate 0.01 Mem size  43622\n",
            "Episode  85: score -14.862114900506398 Episode 85 Score: -14.862114900506398 AVG_score: -75.42346184983033 AVG_REWARD -163.25947378583353 Exploration rate 0.01 Mem size  43885\n",
            "Episode  86: score -147.2266080739389 Episode 86 Score: -147.2266080739389 AVG_score: -76.25838215476183 AVG_REWARD -162.24783318547225 Exploration rate 0.01 Mem size  44672\n",
            "Episode  87: score 210.37601035420738 Episode 87 Score: 210.37601035420738 AVG_score: -72.96373396500357 AVG_REWARD -161.22157917144386 Exploration rate 0.01 Mem size  45006\n",
            "Episode  88: score 244.04699674843758 Episode 88 Score: 244.04699674843758 AVG_score: -69.36133929780537 AVG_REWARD -160.17771280924345 Exploration rate 0.01 Mem size  45625\n",
            "Episode  89: score 218.72423429437157 Episode 89 Score: 218.72423429437157 AVG_score: -66.12442274058989 AVG_REWARD -159.1209342691462 Exploration rate 0.01 Mem size  46145\n",
            "Episode  90: score -69.30319684320543 Episode 90 Score: -69.30319684320543 AVG_score: -66.15974245284117 AVG_REWARD -158.08803213785393 Exploration rate 0.01 Mem size  47145\n",
            "Episode  91: score 206.56686481828808 Episode 91 Score: 206.56686481828808 AVG_score: -63.16274676854305 AVG_REWARD -157.04489713379556 Exploration rate 0.01 Mem size  47621\n",
            "Episode  92: score -98.08935925716082 Episode 92 Score: -98.08935925716082 AVG_score: -63.54238386081064 AVG_REWARD -156.02856546778486 Exploration rate 0.01 Mem size  48621\n",
            "Episode  93: score 271.82837777856923 Episode 93 Score: 271.82837777856923 AVG_score: -59.936246638881826 AVG_REWARD -154.99531472768913 Exploration rate 0.01 Mem size  49241\n",
            "Episode  94: score 203.0380073955337 Episode 94 Score: 203.0380073955337 AVG_score: -57.13864819170719 AVG_REWARD -153.95428636028507 Exploration rate 0.01 Mem size  49673\n",
            "Episode  95: score 224.83721040187342 Episode 95 Score: 224.83721040187342 AVG_score: -54.17048125914318 AVG_REWARD -152.90393051711516 Exploration rate 0.01 Mem size  50024\n",
            "Episode  96: score -373.0922813740184 Episode 96 Score: -373.0922813740184 AVG_score: -57.492583343673125 AVG_REWARD -151.91006231739178 Exploration rate 0.01 Mem size  50533\n",
            "Episode  97: score -24.370172392010033 Episode 97 Score: -24.370172392010033 AVG_score: -57.15111518953228 AVG_REWARD -150.9331659552489 Exploration rate 0.01 Mem size  50641\n",
            "Episode  98: score 1.974933426636099 Episode 98 Score: 1.974933426636099 AVG_score: -56.547788162836675 AVG_REWARD -149.97004985532632 Exploration rate 0.01 Mem size  50889\n",
            "Episode  99: score -159.54169548144858 Episode 99 Score: -159.54169548144858 AVG_score: -57.58813066100447 AVG_REWARD -149.0368991563938 Exploration rate 0.01 Mem size  51098\n",
            "Episode 100: score 177.81716094370802 Episode 100 Score: 177.81716094370802 AVG_score: -55.23407774495735 AVG_REWARD -148.0988709422794 Exploration rate 0.01 Mem size  51517\n",
            "Episode 101: score 138.55968017615086 Episode 101 Score: 138.55968017615086 AVG_score: -50.80162565639217 AVG_REWARD -145.56003191203968 Exploration rate 0.01 Mem size  52207\n",
            "Episode 102: score -349.89983549562373 Episode 102 Score: -349.89983549562373 AVG_score: -52.660302301283394 AVG_REWARD -143.74304643661816 Exploration rate 0.01 Mem size  53110\n",
            "Episode 103: score -27.93425475948166 Episode 103 Score: -27.93425475948166 AVG_score: -49.45932662564297 AVG_REWARD -141.51514129617328 Exploration rate 0.01 Mem size  53297\n",
            "Episode 104: score -43.630698494265005 Episode 104 Score: -43.630698494265005 AVG_score: -48.92369016218758 AVG_REWARD -139.7195185306697 Exploration rate 0.01 Mem size  54297\n",
            "Episode 105: score -50.65557496675383 Episode 105 Score: -50.65557496675383 AVG_score: -47.08511502847221 AVG_REWARD -137.89345577057745 Exploration rate 0.01 Mem size  54551\n",
            "Episode 106: score -56.752866204665295 Episode 106 Score: -56.752866204665295 AVG_score: -45.62055235942352 AVG_REWARD -136.09688448034166 Exploration rate 0.01 Mem size  54668\n",
            "Episode 107: score -190.08576598627775 Episode 107 Score: -190.08576598627775 AVG_score: -44.13718473633161 AVG_REWARD -134.1238440182857 Exploration rate 0.01 Mem size  55109\n",
            "Episode 108: score -496.85039968606696 Episode 108 Score: -496.85039968606696 AVG_score: -46.90114638391629 AVG_REWARD -132.20467691772348 Exploration rate 0.01 Mem size  55851\n",
            "Episode 109: score 217.14729696926042 Episode 109 Score: 217.14729696926042 AVG_score: -41.46956084109337 AVG_REWARD -130.13431240520762 Exploration rate 0.01 Mem size  56508\n",
            "Episode 110: score -121.81888414355643 Episode 110 Score: -121.81888414355643 AVG_score: -38.9563067445415 AVG_REWARD -127.91417707002016 Exploration rate 0.01 Mem size  56888\n",
            "Episode 111: score -118.58389403983718 Episode 111 Score: -118.58389403983718 AVG_score: -35.2182510556263 AVG_REWARD -125.44627970279076 Exploration rate 0.01 Mem size  57236\n",
            "Episode 112: score -76.54307934031596 Episode 112 Score: -76.54307934031596 AVG_score: -31.642374845932085 AVG_REWARD -122.81585464635515 Exploration rate 0.01 Mem size  57501\n",
            "Episode 113: score -83.931855588422 Episode 113 Score: -83.931855588422 AVG_score: -31.635229511061446 AVG_REWARD -120.34692620688925 Exploration rate 0.01 Mem size  58501\n",
            "Episode 114: score 3.1552997311834616 Episode 114 Score: 3.1552997311834616 AVG_score: -28.017279906209236 AVG_REWARD -117.78459570902028 Exploration rate 0.01 Mem size  58638\n",
            "Episode 115: score -54.251530870890676 Episode 115 Score: -54.251530870890676 AVG_score: -25.228785453409568 AVG_REWARD -115.16181316898482 Exploration rate 0.01 Mem size  58761\n",
            "Episode 116: score -227.69698801565693 Episode 116 Score: -227.69698801565693 AVG_score: -24.443185242530145 AVG_REWARD -112.5194558958114 Exploration rate 0.01 Mem size  58999\n",
            "Episode 117: score -97.18233943539273 Episode 117 Score: -97.18233943539273 AVG_score: -23.611345109494895 AVG_REWARD -109.93249349179055 Exploration rate 0.01 Mem size  59474\n",
            "Episode 118: score 168.13209944781562 Episode 118 Score: 168.13209944781562 AVG_score: -18.265733381788788 AVG_REWARD -107.24534081059754 Exploration rate 0.01 Mem size  59745\n",
            "Episode 119: score -106.26677946099088 Episode 119 Score: -106.26677946099088 AVG_score: -17.077536896645483 AVG_REWARD -104.57888225588242 Exploration rate 0.01 Mem size  60115\n",
            "Episode 120: score -112.21818471561967 Episode 120 Score: -112.21818471561967 AVG_score: -17.079731031281494 AVG_REWARD -101.99830795307174 Exploration rate 0.01 Mem size  60637\n",
            "Episode 121: score 174.60335304538629 Episode 121 Score: 174.60335304538629 AVG_score: -17.182569960387323 AVG_REWARD -99.63782128110846 Exploration rate 0.01 Mem size  61173\n",
            "Episode 122: score 190.9230972348734 Episode 122 Score: 190.9230972348734 AVG_score: -17.199962387655784 AVG_REWARD -97.48018743210805 Exploration rate 0.01 Mem size  61529\n",
            "Episode 123: score 169.13948403521636 Episode 123 Score: 169.13948403521636 AVG_score: -14.224043108565937 AVG_REWARD -95.33823391354021 Exploration rate 0.01 Mem size  61908\n",
            "Episode 124: score 114.40218076716029 Episode 124 Score: 114.40218076716029 AVG_score: -12.451306932785752 AVG_REWARD -93.24753134911226 Exploration rate 0.01 Mem size  62469\n",
            "Episode 125: score 114.62412770882366 Episode 125 Score: 114.62412770882366 AVG_score: -10.784819344182543 AVG_REWARD -91.20796268168793 Exploration rate 0.01 Mem size  62858\n",
            "Episode 126: score 176.8741690571667 Episode 126 Score: 176.8741690571667 AVG_score: -8.26910057149151 AVG_REWARD -89.19709989494999 Exploration rate 0.01 Mem size  63145\n",
            "Episode 127: score -93.19135238068316 Episode 127 Score: -93.19135238068316 AVG_score: -8.273293980787768 AVG_REWARD -87.22945806741401 Exploration rate 0.01 Mem size  63287\n",
            "Episode 128: score 251.46251793915522 Episode 128 Score: 251.46251793915522 AVG_score: -7.652467788820306 AVG_REWARD -85.39647132634295 Exploration rate 0.01 Mem size  63625\n",
            "Episode 129: score -155.07189204635793 Episode 129 Score: -155.07189204635793 AVG_score: -9.235803382534602 AVG_REWARD -83.64628787542313 Exploration rate 0.01 Mem size  64536\n",
            "Episode 130: score 280.43875175543116 Episode 130 Score: 280.43875175543116 AVG_score: -5.69953208527106 AVG_REWARD -81.89776363503188 Exploration rate 0.01 Mem size  65023\n",
            "Episode 131: score -165.03278014535073 Episode 131 Score: -165.03278014535073 AVG_score: -7.025353202275433 AVG_REWARD -80.21027221473955 Exploration rate 0.01 Mem size  65822\n",
            "Episode 132: score -57.76532644108515 Episode 132 Score: -57.76532644108515 AVG_score: -6.945746500220193 AVG_REWARD -78.55637488323444 Exploration rate 0.01 Mem size  66194\n",
            "Episode 133: score -97.97942912159195 Episode 133 Score: -97.97942912159195 AVG_score: -6.296399407222269 AVG_REWARD -76.89883903268704 Exploration rate 0.01 Mem size  67194\n",
            "Episode 134: score 155.37936213229034 Episode 134 Score: 155.37936213229034 AVG_score: -4.458571736344425 AVG_REWARD -75.26517389940334 Exploration rate 0.01 Mem size  67491\n",
            "Episode 135: score 288.18303986481635 Episode 135 Score: 288.18303986481635 AVG_score: -0.6981752463512692 AVG_REWARD -73.61675293719979 Exploration rate 0.01 Mem size  67826\n",
            "Episode 136: score -120.13239400835369 Episode 136 Score: -120.13239400835369 AVG_score: -1.2425004079275277 AVG_REWARD -72.00150866928308 Exploration rate 0.01 Mem size  68826\n",
            "Episode 137: score 250.20245909774926 Episode 137 Score: 250.20245909774926 AVG_score: 1.7887488533716707 AVG_REWARD -70.38563960069055 Exploration rate 0.01 Mem size  69225\n",
            "Episode 138: score -124.86291967984793 Episode 138 Score: -124.86291967984793 AVG_score: -1.7387708925685041 AVG_REWARD -68.90706868032584 Exploration rate 0.01 Mem size  70225\n",
            "Episode 139: score -90.4953656443929 Episode 139 Score: -90.4953656443929 AVG_score: -1.8180033771343274 AVG_REWARD -67.44647566063787 Exploration rate 0.01 Mem size  71225\n",
            "Episode 140: score 289.6961112033207 Episode 140 Score: 289.6961112033207 AVG_score: 2.7979223705656846 AVG_REWARD -65.93371859391772 Exploration rate 0.01 Mem size  71673\n",
            "Episode 141: score 255.4939234188873 Episode 141 Score: 255.4939234188873 AVG_score: 5.406166405099059 AVG_REWARD -64.42979306350271 Exploration rate 0.01 Mem size  72052\n",
            "Episode 142: score 223.30243365834028 Episode 142 Score: 223.30243365834028 AVG_score: 8.109583751553433 AVG_REWARD -62.922154094301575 Exploration rate 0.01 Mem size  72484\n",
            "Episode 143: score 49.90740808692681 Episode 143 Score: 49.90740808692681 AVG_score: 9.484148394039499 AVG_REWARD -61.41358465472369 Exploration rate 0.01 Mem size  72739\n",
            "Episode 144: score 281.4449526825921 Episode 144 Score: 281.4449526825921 AVG_score: 10.198704599140564 AVG_REWARD -59.97772468212575 Exploration rate 0.01 Mem size  73211\n",
            "Episode 145: score -205.63977300879458 Episode 145 Score: -205.63977300879458 AVG_score: 8.584900379929364 AVG_REWARD -58.577808960958365 Exploration rate 0.01 Mem size  73471\n",
            "Episode 146: score 133.491508544696 Episode 146 Score: 133.491508544696 AVG_score: 7.784977008339873 AVG_REWARD -57.260868672950444 Exploration rate 0.01 Mem size  74034\n",
            "Episode 147: score 239.44198513484795 Episode 147 Score: 239.44198513484795 AVG_score: 10.555456293759908 AVG_REWARD -55.93458595557458 Exploration rate 0.01 Mem size  74451\n",
            "Episode 148: score -277.66279377428543 Episode 148 Score: -277.66279377428543 AVG_score: 8.458934104456187 AVG_REWARD -54.64053142688338 Exploration rate 0.01 Mem size  75136\n",
            "Episode 149: score 244.84898947682868 Episode 149 Score: 244.84898947682868 AVG_score: 11.378612799639695 AVG_REWARD -53.33234697628589 Exploration rate 0.01 Mem size  75536\n",
            "Episode 150: score 131.6141612035674 Episode 150 Score: 131.6141612035674 AVG_score: 13.159823510712618 AVG_REWARD -52.02093700304896 Exploration rate 0.01 Mem size  76536\n",
            "Episode 151: score 239.42420282320688 Episode 151 Score: 239.42420282320688 AVG_score: 17.412881988517537 AVG_REWARD -50.65368262716253 Exploration rate 0.01 Mem size  77001\n",
            "Episode 152: score 190.53510228851553 Episode 152 Score: 190.53510228851553 AVG_score: 17.740891998605562 AVG_REWARD -49.336426354421356 Exploration rate 0.01 Mem size  77834\n",
            "Episode 153: score 30.823190207598287 Episode 153 Score: 30.823190207598287 AVG_score: 20.105019490088274 AVG_REWARD -47.97824487777193 Exploration rate 0.01 Mem size  78272\n",
            "Episode 154: score -481.2557789286958 Episode 154 Score: -481.2557789286958 AVG_score: 17.25063951407843 AVG_REWARD -46.6337730058543 Exploration rate 0.01 Mem size  79002\n",
            "Episode 155: score 251.89918596416135 Episode 155 Score: 251.89918596416135 AVG_score: 20.69069812275919 AVG_REWARD -45.259462342899624 Exploration rate 0.01 Mem size  79383\n",
            "Episode 156: score 270.7731712459447 Episode 156 Score: 270.7731712459447 AVG_score: 24.363563739684825 AVG_REWARD -43.85203498408392 Exploration rate 0.01 Mem size  79689\n",
            "Episode 157: score -257.2967139240916 Episode 157 Score: -257.2967139240916 AVG_score: 23.703270899436074 AVG_REWARD -42.438072262836094 Exploration rate 0.01 Mem size  80332\n",
            "Episode 158: score 185.6956990412397 Episode 158 Score: 185.6956990412397 AVG_score: 26.131958213746035 AVG_REWARD -41.01025714583061 Exploration rate 0.01 Mem size  80703\n",
            "Episode 159: score 72.1645585638363 Episode 159 Score: 72.1645585638363 AVG_score: 27.636827498151792 AVG_REWARD -39.573889468796324 Exploration rate 0.01 Mem size  81703\n",
            "Episode 160: score -7.3618567131504165 Episode 160 Score: -7.3618567131504165 AVG_score: 28.34688074513374 AVG_REWARD -38.13669338575789 Exploration rate 0.01 Mem size  81858\n",
            "Episode 161: score 193.63567908716885 Episode 161 Score: 193.63567908716885 AVG_score: 28.247221851064033 AVG_REWARD -36.75278475986553 Exploration rate 0.01 Mem size  82335\n",
            "Episode 162: score -250.06616835709679 Episode 162 Score: -250.06616835709679 AVG_score: 25.826284289799414 AVG_REWARD -35.40956473999026 Exploration rate 0.01 Mem size  82848\n",
            "Episode 163: score 248.25305523835337 Episode 163 Score: 248.25305523835337 AVG_score: 28.87245870442709 AVG_REWARD -34.044157790488285 Exploration rate 0.01 Mem size  83092\n",
            "Episode 164: score 196.48621338315263 Episode 164 Score: 196.48621338315263 AVG_score: 31.285225569847547 AVG_REWARD -32.66444782281443 Exploration rate 0.01 Mem size  83498\n",
            "Episode 165: score 247.82279455443637 Episode 165 Score: 247.82279455443637 AVG_score: 37.04078955511868 AVG_REWARD -31.193174856399377 Exploration rate 0.01 Mem size  83855\n",
            "Episode 166: score 227.08777977920826 Episode 166 Score: 227.08777977920826 AVG_score: 37.53350187643206 AVG_REWARD -29.760596441730932 Exploration rate 0.01 Mem size  84125\n",
            "Episode 167: score 257.1489737669984 Episode 167 Score: 257.1489737669984 AVG_score: 40.65276704944199 AVG_REWARD -28.30442937474379 Exploration rate 0.01 Mem size  84737\n",
            "Episode 168: score -50.999072482088025 Episode 168 Score: -50.999072482088025 AVG_score: 38.80490095930162 AVG_REWARD -26.90185147986118 Exploration rate 0.01 Mem size  85737\n",
            "Episode 169: score 184.99246901626492 Episode 169 Score: 184.99246901626492 AVG_score: 38.642973102472745 AVG_REWARD -25.544753464014697 Exploration rate 0.01 Mem size  86301\n",
            "Episode 170: score 258.5745311230034 Episode 170 Score: 258.5745311230034 AVG_score: 41.873968007368546 AVG_REWARD -24.15999433756434 Exploration rate 0.01 Mem size  86920\n",
            "Episode 171: score 216.11831999114307 Episode 171 Score: 216.11831999114307 AVG_score: 43.97814881690375 AVG_REWARD -22.768602161282757 Exploration rate 0.01 Mem size  87366\n",
            "Episode 172: score 194.1573596948225 Episode 172 Score: 194.1573596948225 AVG_score: 46.201531861214924 AVG_REWARD -21.36427894956847 Exploration rate 0.01 Mem size  87651\n",
            "Episode 173: score -253.54458070938506 Episode 173 Score: -253.54458070938506 AVG_score: 44.22798407068841 AVG_REWARD -19.98490230995856 Exploration rate 0.01 Mem size  88646\n",
            "Episode 174: score 180.7816150263655 Episode 174 Score: 180.7816150263655 AVG_score: 46.048373138524894 AVG_REWARD -18.5998153456342 Exploration rate 0.01 Mem size  89001\n",
            "Episode 175: score -154.87695298706046 Episode 175 Score: -154.87695298706046 AVG_score: 45.30569938914135 AVG_REWARD -17.223735218169708 Exploration rate 0.01 Mem size  89514\n",
            "Episode 176: score 167.14448693197443 Episode 176 Score: 167.14448693197443 AVG_score: 47.41404693318613 AVG_REWARD -15.832967937091716 Exploration rate 0.01 Mem size  90412\n",
            "Episode 177: score 224.55885542817262 Episode 177 Score: 224.55885542817262 AVG_score: 50.531188569922755 AVG_REWARD -14.411614612754036 Exploration rate 0.01 Mem size  90834\n",
            "Episode 178: score 208.1612669074321 Episode 178 Score: 208.1612669074321 AVG_score: 50.39054663080984 AVG_REWARD -13.031902272510381 Exploration rate 0.01 Mem size  91163\n",
            "Episode 179: score 214.59783874232573 Episode 179 Score: 214.59783874232573 AVG_score: 52.15963860626689 AVG_REWARD -11.650355889548882 Exploration rate 0.01 Mem size  91418\n",
            "Episode 180: score 276.008375125502 Episode 180 Score: 276.008375125502 AVG_score: 52.951333731864686 AVG_REWARD -10.29624678811336 Exploration rate 0.01 Mem size  91732\n",
            "Episode 181: score 262.84814230613983 Episode 181 Score: 262.84814230613983 AVG_score: 53.334681452383464 AVG_REWARD -8.976202104122768 Exploration rate 0.01 Mem size  92121\n",
            "Episode 182: score -18.151151076536394 Episode 182 Score: -18.151151076536394 AVG_score: 54.825228585804425 AVG_REWARD -7.630454866179433 Exploration rate 0.01 Mem size  92313\n",
            "Episode 183: score 223.58920701528336 Episode 183 Score: 223.58920701528336 AVG_score: 55.123513876182244 AVG_REWARD -6.314677808246299 Exploration rate 0.01 Mem size  92922\n",
            "Episode 184: score 178.2060046569976 Episode 184 Score: 178.2060046569976 AVG_score: 57.409916054884064 AVG_REWARD -4.979134345038521 Exploration rate 0.01 Mem size  93205\n",
            "Episode 185: score -25.47901721651418 Episode 185 Score: -25.47901721651418 AVG_score: 57.30374703172399 AVG_REWARD -3.651862256222978 Exploration rate 0.01 Mem size  93394\n",
            "Episode 186: score 250.45089467666637 Episode 186 Score: 250.45089467666637 AVG_score: 61.28052205923004 AVG_REWARD -2.276473214083059 Exploration rate 0.01 Mem size  93708\n",
            "Episode 187: score 18.37417026162455 Episode 187 Score: 18.37417026162455 AVG_score: 59.36050365830422 AVG_REWARD -0.9532308378499809 Exploration rate 0.01 Mem size  94708\n",
            "Episode 188: score -31.019190212913976 Episode 188 Score: -31.019190212913976 AVG_score: 56.6098417886907 AVG_REWARD 0.30648097301497934 Exploration rate 0.01 Mem size  95708\n",
            "Episode 189: score 204.71180205099856 Episode 189 Score: 204.71180205099856 AVG_score: 56.469717466256974 AVG_REWARD 1.5324223750834483 Exploration rate 0.01 Mem size  96568\n",
            "Episode 190: score 244.15730378238837 Episode 190 Score: 244.15730378238837 AVG_score: 59.604322472512905 AVG_REWARD 2.7900630243369893 Exploration rate 0.01 Mem size  96942\n",
            "Episode 191: score 244.92196779875655 Episode 191 Score: 244.92196779875655 AVG_score: 59.98787350231759 AVG_REWARD 4.021569227045595 Exploration rate 0.01 Mem size  97256\n",
            "Episode 192: score 201.05122163247404 Episode 192 Score: 201.05122163247404 AVG_score: 62.97927931121394 AVG_REWARD 5.286785858765842 Exploration rate 0.01 Mem size  97661\n",
            "Episode 193: score 223.49403275343718 Episode 193 Score: 223.49403275343718 AVG_score: 62.49593586096261 AVG_REWARD 6.511107683764287 Exploration rate 0.01 Mem size  97992\n",
            "Episode 194: score 259.93745272581555 Episode 194 Score: 259.93745272581555 AVG_score: 63.06493031426544 AVG_REWARD 7.713143468824013 Exploration rate 0.01 Mem size  98562\n",
            "Episode 195: score 251.0039491300614 Episode 195 Score: 251.0039491300614 AVG_score: 63.32659770154731 AVG_REWARD 8.888114258430917 Exploration rate 0.01 Mem size  99002\n",
            "Episode 196: score 173.8153353932151 Episode 196 Score: 173.8153353932151 AVG_score: 68.79567386921964 AVG_REWARD 10.150996830559844 Exploration rate 0.01 Mem size  99338\n",
            "Episode 197: score 162.4352707196803 Episode 197 Score: 162.4352707196803 AVG_score: 70.66372830033653 AVG_REWARD 11.429145265458533 Exploration rate 0.01 Mem size  99846\n",
            "Episode 198: score 219.59274120345071 Episode 198 Score: 219.59274120345071 AVG_score: 72.8399063781047 AVG_REWARD 12.723022210867946 Exploration rate 0.01 Mem size  100334\n",
            "Episode 199: score 237.59570353074074 Episode 199 Score: 237.59570353074074 AVG_score: 76.81128036822659 AVG_REWARD 14.067016321160256 Exploration rate 0.01 Mem size  100555\n",
            "Episode 200: score 253.82412106508482 Episode 200 Score: 253.82412106508482 AVG_score: 77.57134996944036 AVG_REWARD 15.395070598304233 Exploration rate 0.01 Mem size  100962\n",
            "Episode 201: score 240.30618796540705 Episode 201 Score: 240.30618796540705 AVG_score: 78.58881504733293 AVG_REWARD 16.688975005341486 Exploration rate 0.01 Mem size  101269\n",
            "Episode 202: score 220.06022893075382 Episode 202 Score: 220.06022893075382 AVG_score: 84.2884156915967 AVG_REWARD 18.058462185270287 Exploration rate 0.01 Mem size  101622\n",
            "Episode 203: score -310.4248706831323 Episode 203 Score: -310.4248706831323 AVG_score: 81.46350953236019 AVG_REWARD 19.367690546850316 Exploration rate 0.01 Mem size  102186\n",
            "Episode 204: score 213.36584054743557 Episode 204 Score: 213.36584054743557 AVG_score: 84.03347492277719 AVG_REWARD 20.697262197699967 Exploration rate 0.01 Mem size  102770\n",
            "Episode 205: score 201.5729360911485 Episode 205 Score: 201.5729360911485 AVG_score: 86.55576003335622 AVG_REWARD 22.03367094831825 Exploration rate 0.01 Mem size  103430\n",
            "Episode 206: score 261.7881140774665 Episode 206 Score: 261.7881140774665 AVG_score: 89.74116983617752 AVG_REWARD 23.387288170274264 Exploration rate 0.01 Mem size  103695\n",
            "Episode 207: score 274.3174243064918 Episode 207 Score: 274.3174243064918 AVG_score: 94.38520173910523 AVG_REWARD 24.77251203502863 Exploration rate 0.01 Mem size  103997\n",
            "Episode 208: score 256.75935785857337 Episode 208 Score: 256.75935785857337 AVG_score: 101.92129931455162 AVG_REWARD 26.260736492013308 Exploration rate 0.01 Mem size  104307\n",
            "Episode 209: score 8.900495395103917 Episode 209 Score: 8.900495395103917 AVG_score: 99.83883129881008 AVG_REWARD 27.67382041341234 Exploration rate 0.01 Mem size  104479\n",
            "Episode 210: score 240.10667813681505 Episode 210 Score: 240.10667813681505 AVG_score: 103.45808692161377 AVG_REWARD 29.097964350073894 Exploration rate 0.01 Mem size  105251\n",
            "Episode 211: score -10.741969392474559 Episode 211 Score: -10.741969392474559 AVG_score: 104.53650616808741 AVG_REWARD 30.495511922311028 Exploration rate 0.01 Mem size  105418\n",
            "Episode 212: score 89.49437018500744 Episode 212 Score: 89.49437018500744 AVG_score: 106.19688066334065 AVG_REWARD 31.873904477403762 Exploration rate 0.01 Mem size  106315\n",
            "Episode 213: score 85.12582766934224 Episode 213 Score: 85.12582766934224 AVG_score: 107.8874574959183 AVG_REWARD 33.26913134747356 Exploration rate 0.01 Mem size  107315\n",
            "Episode 214: score 232.45663227478212 Episode 214 Score: 232.45663227478212 AVG_score: 110.18047082135426 AVG_REWARD 34.6511088547492 Exploration rate 0.01 Mem size  108287\n",
            "Episode 215: score 274.30133896976696 Episode 215 Score: 274.30133896976696 AVG_score: 113.46599951976084 AVG_REWARD 36.038056704480894 Exploration rate 0.01 Mem size  108542\n",
            "Episode 216: score 238.5065751449485 Episode 216 Score: 238.5065751449485 AVG_score: 118.12803515136689 AVG_REWARD 37.463768908419866 Exploration rate 0.01 Mem size  108848\n",
            "Episode 217: score 279.34618205734523 Episode 217 Score: 279.34618205734523 AVG_score: 121.89332036629426 AVG_REWARD 38.91881556317776 Exploration rate 0.01 Mem size  109261\n",
            "Episode 218: score 270.92552632944796 Episode 218 Score: 270.92552632944796 AVG_score: 122.9212546351106 AVG_REWARD 40.330685443346745 Exploration rate 0.01 Mem size  109556\n",
            "Episode 219: score -91.3308662813174 Episode 219 Score: -91.3308662813174 AVG_score: 123.07061376690734 AVG_REWARD 41.73216694998227 Exploration rate 0.01 Mem size  109662\n",
            "Episode 220: score 196.3318512614557 Episode 220 Score: 196.3318512614557 AVG_score: 126.15611412667808 AVG_REWARD 43.164525401561875 Exploration rate 0.01 Mem size  110103\n",
            "Episode 221: score 247.91232329159345 Episode 221 Score: 247.91232329159345 AVG_score: 126.88920382914013 AVG_REWARD 44.60524313945716 Exploration rate 0.01 Mem size  110383\n",
            "Episode 222: score 211.13189437488106 Episode 222 Score: 211.13189437488106 AVG_score: 127.09129180054023 AVG_REWARD 46.04815568133913 Exploration rate 0.01 Mem size  111035\n",
            "Episode 223: score 240.054564693582 Episode 223 Score: 240.054564693582 AVG_score: 127.8004426071239 AVG_REWARD 47.46840053849601 Exploration rate 0.01 Mem size  111571\n",
            "Episode 224: score 250.59150388400775 Episode 224 Score: 250.59150388400775 AVG_score: 129.1623358382924 AVG_REWARD 48.884536966206795 Exploration rate 0.01 Mem size  111809\n",
            "Episode 225: score 236.46659980249976 Episode 225 Score: 236.46659980249976 AVG_score: 130.38076055922912 AVG_REWARD 50.29619276524091 Exploration rate 0.01 Mem size  112075\n",
            "Episode 226: score 10.816389567028537 Episode 226 Score: 10.816389567028537 AVG_score: 128.72018276432775 AVG_REWARD 51.666085598599096 Exploration rate 0.01 Mem size  112248\n",
            "Episode 227: score 240.718755474725 Episode 227 Score: 240.718755474725 AVG_score: 132.05928384288183 AVG_REWARD 53.069411376835795 Exploration rate 0.01 Mem size  112495\n",
            "Episode 228: score 270.0737172843921 Episode 228 Score: 270.0737172843921 AVG_score: 132.24539583633418 AVG_REWARD 54.46839001308734 Exploration rate 0.01 Mem size  112807\n",
            "Episode 229: score 250.42286105299712 Episode 229 Score: 250.42286105299712 AVG_score: 136.30034336732774 AVG_REWARD 55.92375148058596 Exploration rate 0.01 Mem size  113270\n",
            "Episode 230: score 207.53678377043676 Episode 230 Score: 207.53678377043676 AVG_score: 135.5713236874778 AVG_REWARD 57.336460038313454 Exploration rate 0.01 Mem size  113648\n",
            "Episode 231: score 228.53050649758438 Episode 231 Score: 228.53050649758438 AVG_score: 139.50695655390714 AVG_REWARD 58.801783135875276 Exploration rate 0.01 Mem size  114107\n",
            "Episode 232: score 273.62693051639656 Episode 232 Score: 273.62693051639656 AVG_score: 142.82087912348197 AVG_REWARD 60.2994493921123 Exploration rate 0.01 Mem size  114462\n",
            "Episode 233: score 260.4434498460082 Episode 233 Score: 260.4434498460082 AVG_score: 146.40510791315796 AVG_REWARD 61.82646446531609 Exploration rate 0.01 Mem size  114810\n",
            "Episode 234: score -87.64135789159027 Episode 234 Score: -87.64135789159027 AVG_score: 143.97490071291918 AVG_REWARD 63.31079918980874 Exploration rate 0.01 Mem size  114934\n",
            "Episode 235: score 243.42470492126216 Episode 235 Score: 243.42470492126216 AVG_score: 143.52731736348363 AVG_REWARD 64.75305411590709 Exploration rate 0.01 Mem size  115241\n",
            "Episode 236: score 248.2148041019777 Episode 236 Score: 248.2148041019777 AVG_score: 147.21078934458694 AVG_REWARD 66.23758701343223 Exploration rate 0.01 Mem size  115494\n",
            "Episode 237: score 276.60741177681814 Episode 237 Score: 276.60741177681814 AVG_score: 147.47483887137764 AVG_REWARD 67.69444791361231 Exploration rate 0.01 Mem size  115769\n",
            "Episode 238: score 252.53487359532053 Episode 238 Score: 252.53487359532053 AVG_score: 151.24881680412932 AVG_REWARD 69.22432379057928 Exploration rate 0.01 Mem size  116372\n",
            "Episode 239: score -160.264082497115 Episode 239 Score: -160.264082497115 AVG_score: 150.5511296356021 AVG_REWARD 70.74801512070663 Exploration rate 0.01 Mem size  116629\n",
            "Episode 240: score 264.88222121708986 Episode 240 Score: 264.88222121708986 AVG_score: 150.3029907357398 AVG_REWARD 72.22306580435837 Exploration rate 0.01 Mem size  116903\n",
            "Episode 241: score -149.3547170693164 Episode 241 Score: -149.3547170693164 AVG_score: 146.25450433085774 AVG_REWARD 73.63154918361596 Exploration rate 0.01 Mem size  117203\n",
            "Episode 242: score 264.2670713542077 Episode 242 Score: 264.2670713542077 AVG_score: 146.66415070781648 AVG_REWARD 75.01709485317859 Exploration rate 0.01 Mem size  117712\n",
            "Episode 243: score 182.00107867189587 Episode 243 Score: 182.00107867189587 AVG_score: 147.98508741366612 AVG_REWARD 76.40210424337486 Exploration rate 0.01 Mem size  118141\n",
            "Episode 244: score -222.70674208684588 Episode 244 Score: -222.70674208684588 AVG_score: 142.94357046597176 AVG_REWARD 77.72955290204317 Exploration rate 0.01 Mem size  118448\n",
            "Episode 245: score 36.376712361807506 Episode 245 Score: 36.376712361807506 AVG_score: 145.36373531967777 AVG_REWARD 79.09734125144067 Exploration rate 0.01 Mem size  118620\n",
            "Episode 246: score 6.059328730502983 Episode 246 Score: 6.059328730502983 AVG_score: 144.08941352153585 AVG_REWARD 80.46038561657264 Exploration rate 0.01 Mem size  118745\n",
            "Episode 247: score 258.5819404242468 Episode 247 Score: 258.5819404242468 AVG_score: 144.28081307442983 AVG_REWARD 81.79763918437932 Exploration rate 0.01 Mem size  119147\n",
            "Episode 248: score 273.2309858198544 Episode 248 Score: 273.2309858198544 AVG_score: 149.78975087037122 AVG_REWARD 83.21094735203847 Exploration rate 0.01 Mem size  119618\n",
            "Episode 249: score 265.7682286427613 Episode 249 Score: 265.7682286427613 AVG_score: 149.99894326203056 AVG_REWARD 84.5971506566624 Exploration rate 0.01 Mem size  119906\n",
            "Episode 250: score 16.8154906930031 Episode 250 Score: 16.8154906930031 AVG_score: 148.8509565569249 AVG_REWARD 85.95406198712452 Exploration rate 0.01 Mem size  120140\n",
            "Episode 251: score 222.15357935774267 Episode 251 Score: 222.15357935774267 AVG_score: 148.67825032227026 AVG_REWARD 87.26671567046203 Exploration rate 0.01 Mem size  120588\n",
            "Episode 252: score 262.9393766558819 Episode 252 Score: 262.9393766558819 AVG_score: 149.4022930659439 AVG_REWARD 88.5833296811354 Exploration rate 0.01 Mem size  121115\n",
            "Episode 253: score 252.50359194777522 Episode 253 Score: 252.50359194777522 AVG_score: 151.6190970833457 AVG_REWARD 89.89847045706796 Exploration rate 0.01 Mem size  121401\n",
            "Episode 254: score 283.5791558832116 Episode 254 Score: 283.5791558832116 AVG_score: 159.26744643146478 AVG_REWARD 91.31863852624181 Exploration rate 0.01 Mem size  121692\n",
            "Episode 255: score 251.74255669802486 Episode 255 Score: 251.74255669802486 AVG_score: 159.26588013880342 AVG_REWARD 92.70439034640226 Exploration rate 0.01 Mem size  121984\n",
            "Episode 256: score 242.34913893900148 Episode 256 Score: 242.34913893900148 AVG_score: 158.98163981573398 AVG_REWARD 94.0505711071628 Exploration rate 0.01 Mem size  122271\n",
            "Episode 257: score -202.95239536842223 Episode 257 Score: -202.95239536842223 AVG_score: 159.52508300129068 AVG_REWARD 95.40878922818132 Exploration rate 0.01 Mem size  123271\n",
            "Episode 258: score 203.16436451843822 Episode 258 Score: 203.16436451843822 AVG_score: 159.69976965606264 AVG_REWARD 96.7444673426045 Exploration rate 0.01 Mem size  123682\n",
            "Episode 259: score 237.46216230049652 Episode 259 Score: 237.46216230049652 AVG_score: 161.35274569342926 AVG_REWARD 98.08162652455727 Exploration rate 0.01 Mem size  124187\n",
            "Episode 260: score 276.61778852444803 Episode 260 Score: 276.61778852444803 AVG_score: 164.19254214580525 AVG_REWARD 99.44008313856399 Exploration rate 0.01 Mem size  124468\n",
            "Episode 261: score 219.75430452420989 Episode 261 Score: 219.75430452420989 AVG_score: 164.45372840017563 AVG_REWARD 100.8021482040551 Exploration rate 0.01 Mem size  124957\n",
            "Episode 262: score 236.49184108544318 Episode 262 Score: 236.49184108544318 AVG_score: 169.31930849460107 AVG_REWARD 102.23707844610311 Exploration rate 0.01 Mem size  125469\n",
            "Episode 263: score 216.2059622233873 Episode 263 Score: 216.2059622233873 AVG_score: 168.99883756445138 AVG_REWARD 103.63834223470336 Exploration rate 0.01 Mem size  126253\n",
            "Episode 264: score 271.3117200307788 Episode 264 Score: 271.3117200307788 AVG_score: 169.74709263092763 AVG_REWARD 105.02296090531416 Exploration rate 0.01 Mem size  126538\n",
            "Episode 265: score 233.88875431884156 Episode 265 Score: 233.88875431884156 AVG_score: 169.6077522285717 AVG_REWARD 106.34863053204869 Exploration rate 0.01 Mem size  126866\n",
            "Episode 266: score 270.71520495720534 Episode 266 Score: 270.71520495720534 AVG_score: 170.04402648035168 AVG_REWARD 107.67373577808789 Exploration rate 0.01 Mem size  127107\n",
            "Episode 267: score 247.91589661124775 Episode 267 Score: 247.91589661124775 AVG_score: 169.95169570879418 AVG_REWARD 108.9667250646814 Exploration rate 0.01 Mem size  127565\n",
            "Episode 268: score 210.1462602942978 Episode 268 Score: 210.1462602942978 AVG_score: 172.56314903655806 AVG_REWARD 110.30430754545395 Exploration rate 0.01 Mem size  128182\n",
            "Episode 269: score 257.3577895018777 Episode 269 Score: 257.3577895018777 AVG_score: 173.2868022414142 AVG_REWARD 111.65074583684338 Exploration rate 0.01 Mem size  128761\n",
            "Episode 270: score 6.42620886282204 Episode 270 Score: 6.42620886282204 AVG_score: 170.76531901881236 AVG_REWARD 112.93965934695781 Exploration rate 0.01 Mem size  129761\n",
            "Episode 271: score 264.13184508418317 Episode 271 Score: 264.13184508418317 AVG_score: 171.24545426974277 AVG_REWARD 114.21233240148622 Exploration rate 0.01 Mem size  130080\n",
            "Episode 272: score -59.73064377832039 Episode 272 Score: -59.73064377832039 AVG_score: 168.70657423501135 AVG_REWARD 115.43738282522418 Exploration rate 0.01 Mem size  130781\n",
            "Episode 273: score -7.846688363140103 Episode 273 Score: -7.846688363140103 AVG_score: 171.16355315847377 AVG_REWARD 116.70673851610205 Exploration rate 0.01 Mem size  131023\n",
            "Episode 274: score 245.95017337616088 Episode 274 Score: 245.95017337616088 AVG_score: 171.8152387419717 AVG_REWARD 117.9644071721365 Exploration rate 0.01 Mem size  131307\n",
            "Episode 275: score 266.88990837092376 Episode 275 Score: 266.88990837092376 AVG_score: 176.03290735555154 AVG_REWARD 119.27167925180062 Exploration rate 0.01 Mem size  131768\n",
            "Episode 276: score 213.68839430647466 Episode 276 Score: 213.68839430647466 AVG_score: 176.4983464292965 AVG_REWARD 120.56252224676172 Exploration rate 0.01 Mem size  132615\n",
            "Episode 277: score 276.02411358010386 Episode 277 Score: 276.02411358010386 AVG_score: 177.01299901081583 AVG_REWARD 121.82734035117065 Exploration rate 0.01 Mem size  132868\n",
            "Episode 278: score 180.53111658161384 Episode 278 Score: 180.53111658161384 AVG_score: 176.7366975075577 AVG_REWARD 123.09080185993813 Exploration rate 0.01 Mem size  133782\n",
            "Episode 279: score 289.6915158359992 Episode 279 Score: 289.6915158359992 AVG_score: 177.4876342784944 AVG_REWARD 124.34408181666038 Exploration rate 0.01 Mem size  134043\n",
            "Episode 280: score 78.33974121357747 Episode 280 Score: 78.33974121357747 AVG_score: 175.51094793937517 AVG_REWARD 125.5696779587355 Exploration rate 0.01 Mem size  135043\n",
            "Episode 281: score 218.54859370054965 Episode 281 Score: 218.54859370054965 AVG_score: 175.0679524533193 AVG_REWARD 126.78701066874484 Exploration rate 0.01 Mem size  135540\n",
            "Episode 282: score 250.06315373678484 Episode 282 Score: 250.06315373678484 AVG_score: 177.75009550145253 AVG_REWARD 128.01625933790135 Exploration rate 0.01 Mem size  135798\n",
            "Episode 283: score 212.27783732210779 Episode 283 Score: 212.27783732210779 AVG_score: 177.63698180452076 AVG_REWARD 129.24139401718472 Exploration rate 0.01 Mem size  136408\n",
            "Episode 284: score 275.2398545891915 Episode 284 Score: 275.2398545891915 AVG_score: 178.60732030384267 AVG_REWARD 130.4533680596743 Exploration rate 0.01 Mem size  136794\n",
            "Episode 285: score 261.97352123289375 Episode 285 Score: 261.97352123289375 AVG_score: 181.48184568833676 AVG_REWARD 131.69514904624043 Exploration rate 0.01 Mem size  137335\n",
            "Episode 286: score -156.82372349177197 Episode 286 Score: -156.82372349177197 AVG_score: 177.40909950665235 AVG_REWARD 132.85643482071467 Exploration rate 0.01 Mem size  137501\n",
            "Episode 287: score 208.4726437520706 Episode 287 Score: 208.4726437520706 AVG_score: 179.3100842415568 AVG_REWARD 134.0559306265472 Exploration rate 0.01 Mem size  137897\n",
            "Episode 288: score -46.96360077644353 Episode 288 Score: -46.96360077644353 AVG_score: 179.1506401359215 AVG_REWARD 135.2813386100195 Exploration rate 0.01 Mem size  138113\n",
            "Episode 289: score 291.31150294150245 Episode 289 Score: 291.31150294150245 AVG_score: 180.01663714482657 AVG_REWARD 136.51680780680522 Exploration rate 0.01 Mem size  138358\n",
            "Episode 290: score 241.98724025241728 Episode 290 Score: 241.98724025241728 AVG_score: 179.99493650952684 AVG_REWARD 137.72071394717534 Exploration rate 0.01 Mem size  138688\n",
            "Episode 291: score -67.89461922660948 Episode 291 Score: -67.89461922660948 AVG_score: 176.8667706392732 AVG_REWARD 138.8895029185449 Exploration rate 0.01 Mem size  138917\n",
            "Episode 292: score 250.1507775088128 Episode 292 Score: 250.1507775088128 AVG_score: 177.3577661980366 AVG_REWARD 140.03328778741312 Exploration rate 0.01 Mem size  139292\n",
            "Episode 293: score 199.03839221843188 Episode 293 Score: 199.03839221843188 AVG_score: 177.1132097926865 AVG_REWARD 141.17946052673034 Exploration rate 0.01 Mem size  139948\n",
            "Episode 294: score 168.23989853469834 Episode 294 Score: 168.23989853469834 AVG_score: 176.19623425077535 AVG_REWARD 142.31077356609546 Exploration rate 0.01 Mem size  140829\n",
            "Episode 295: score -194.31639445876232 Episode 295 Score: -194.31639445876232 AVG_score: 171.74303081488713 AVG_REWARD 143.39493789722883 Exploration rate 0.01 Mem size  141582\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b523414f33b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Learn using a batch of experience stored in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Detect end of episode and print\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-97ae052a044c>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mq_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mq_next_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#modify esto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mnext_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2000\u001b[0m               stacklevel=2)\n\u001b[1;32m   2001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2002\u001b[0;31m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   2003\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1399\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1152\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[0;34m(self, map_func, name)\u001b[0m\n\u001b[1;32m   2090\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2091\u001b[0m     \"\"\"\n\u001b[0;32m-> 2092\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2094\u001b[0m   def interleave(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m   5325\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5326\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5327\u001b[0;31m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m   5328\u001b[0m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[1;32m   5329\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2565\u001b[0m          \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m     \"\"\"\n\u001b[0;32m-> 2567\u001b[0;31m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m   2568\u001b[0m         *args, **kwargs)\n\u001b[1;32m   2569\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2531\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2533\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2534\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2535\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2709\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_placeholder_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2711\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2712\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   2713\u001b[0m                                    graph_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2625\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2626\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2627\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1054\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m     \u001b[0mfunc_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_defun_inputs_from_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m     \u001b[0mfunc_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_defun_inputs_from_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_get_defun_inputs_from_args\u001b[0;34m(args, names)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_defun_inputs_from_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;34m\"\"\"Maps Python function positional args to graph-construction inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_get_defun_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructured_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_get_defun_inputs\u001b[0;34m(args, names, structured_args)\u001b[0m\n\u001b[1;32m   1373\u001b[0m           \u001b[0mrequested_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m           placeholder = graph_placeholder(\n\u001b[0m\u001b[1;32m   1376\u001b[0m               arg.dtype, arg.shape, name=requested_name)\n\u001b[1;32m   1377\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/graph_only_ops.py\u001b[0m in \u001b[0;36mgraph_placeholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   op = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m     35\u001b[0m       \u001b[0;34m\"Placeholder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m       attrs=attrs, name=name)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    692\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    695\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         compute_device)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3752\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3753\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3754\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3755\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3756\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2131\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_stack_for_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/tf_stack.py\u001b[0m in \u001b[0;36mextract_stack_for_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[0;31m# traversing the stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m   \u001b[0mthread_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_thread_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m   return _tf_stack.extract_stack_for_node(\n\u001b[0m\u001b[1;32m    184\u001b[0m       \u001b[0m_source_mapper_stacks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthread_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m       _source_filter_stacks[thread_key][-1].internal_set, node)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "environment, number_of_observations, number_of_actions = create_environment()\n",
        "agent = DQN(number_of_observations, number_of_actions)\n",
        "episode = 0\n",
        "goal_reached = False\n",
        "start_time = time.perf_counter()\n",
        "#environment.reset()\n",
        "#prev_screen = environment.render(mode='rgb_array')\n",
        "\n",
        "#plt.imshow(prev_screen)\n",
        "global_step =0 #la idea seria entrenar solo cada 4 samples, pero seria interesante hacer la memoria más pequeñita\n",
        "puntuaciones, avg_r,r = [],[],[]\n",
        "while (episode < NUMBER_OF_EPISODES) and not (goal_reached):\n",
        "    episode += 1\n",
        "    step = 1\n",
        "    end_episode = False\n",
        "    state = environment.reset()\n",
        "    avg_reward =0\n",
        "    episode_reward =0\n",
        "    while not(end_episode):\n",
        "        # Select an action for the current state\n",
        "        action = agent.select(state)\n",
        "        global_step +=1\n",
        "\n",
        "        # Execute the action in the environment\n",
        "        state_next, reward, terminal_state, info = environment.step(action)\n",
        "        \"\"\"\n",
        "        Revienta todo si hacemos esto durante entrenamiento, idea feliz? grabar una vez la red este entrenada\n",
        "        screen = environment.render(mode='rgb_array')plt.imshow(screen)\n",
        "        ipythondisplay.clear_output(wait=True)\n",
        "        ipythondisplay.display(plt.gcf())\"\"\"\n",
        "        avg_reward +=reward\n",
        "        episode_reward +=reward\n",
        "        # Store in memory the transition (s,a,r,s') \n",
        "        agent.remember(state, action, reward, state_next, terminal_state)\n",
        "        # Learn using a batch of experience stored in memory\n",
        "        if global_step % 4 ==0:\n",
        "          agent.learn() \n",
        "  \n",
        "        # Detect end of episode and print\n",
        "        if terminal_state:\n",
        "            agent.add_score(episode_reward)#duda fuerte: utilizar episode reward o reward?\n",
        "            # esta es la linea a modificar de condicion de paradaif step >= MAX_STEPS: goal_reached = True\n",
        "            if np.mean(puntuaciones[-14:]) >= 200:\n",
        "               print(\"GOAL REACHED\", reward, avg_reward, avg_reward/step, step)\n",
        "               goal_reached=True\n",
        "            print(\"Episode {0:>3}: \".format(episode), end = '')\n",
        "            print(\"score {0:>3} \".format(episode_reward), end = '')\n",
        "            end_episode = True \n",
        "        else:\n",
        "            state = state_next\n",
        "            step += 1\n",
        "    puntuaciones.append(episode_reward)\n",
        "    avg_r.append(np.mean(puntuaciones[-100:]))\n",
        "    print(f\"Episode {episode} Score: {episode_reward} AVG_score: {np.mean(puntuaciones[-100:])} AVG_REWARD {np.mean(avg_r[-100:])} Exploration rate {agent.exploration_rate} Mem size  {agent.memory.current_size}\")\n",
        "#ipythondisplay.clear_output(wait=True)\n",
        "#environment.close()\n",
        "if goal_reached: print(\"Reached goal sucessfully.\")\n",
        "else: print(\"Failure to reach the goal.\")\n",
        "\n",
        "print (\"Time:\", round((time.perf_counter() - start_time)/60), \"minutes\")\n",
        "\n",
        "agent.display_scores_graphically()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for episode in range(10): #eval durante 10 epis\n",
        "  total_rewards =0\n",
        "  state = environment.reset()\n",
        "  print(f'Episode {episode}')\n",
        "  print('------------')\n",
        "  avg_reward=0\n",
        "  episode_reward=0\n",
        "  while True:\n",
        "        action = agent.select(state)\n",
        "\n",
        "        # Execute the action in the environment\n",
        "        state_next, reward, terminal_state, info = environment.step(action)\n",
        "       \n",
        "        avg_reward +=reward\n",
        "        episode_reward +=reward\n",
        "        state = state_next\n",
        "        if terminal_state:\n",
        "          break\n",
        "  print(avg_reward)\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP8DgMYbYM_g",
        "outputId": "53f2c1d9-b506-46ba-d7b9-e308ea86ae8d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------\n",
            "-97.88377079960044\n",
            "------------\n",
            "-362.3413506051505\n",
            "------------\n",
            "-123.78886761314018\n",
            "------------\n",
            "226.4976683076719\n",
            "------------\n",
            "268.27550478864396\n",
            "------------\n",
            "-121.86014277208906\n",
            "------------\n",
            "-85.87002416398403\n",
            "------------\n",
            "224.8722318239724\n",
            "------------\n",
            "-90.82063853646156\n",
            "------------\n",
            "270.9610624964699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.display_scores_graphically()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "In5OG6zwZ5UW",
        "outputId": "b6a3ec4a-e341-4b78-ac22-59f867debfa6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}